import asyncio

from aiogram import Router, F
from aiogram.types import Message

from ..services.storage import ensure_user, get_current_mode
from ..services.llm import llm_client, infer_style_from_text
from ..services.analytics import increment_usage, estimate_tokens

router = Router(name="chat")

_MENU_TEXTS = {
    "üß† –†–µ–∂–∏–º—ã",
    "üë§ –ü—Ä–æ—Ñ–∏–ª—å",
    "üíé –ü–æ–¥–ø–∏—Å–∫–∞",
    "üë• –†–µ—Ñ–µ—Ä–∞–ª—ã",
    "‚¨ÖÔ∏è –ù–∞–∑–∞–¥",
    "üß† –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π",
    "üíº –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π",
    "üî• –ù–∞—Å—Ç–∞–≤–Ω–∏–∫",
    "ü©∫ –ú–µ–¥–∏—Ü–∏–Ω–∞",
    "üíé 1 –º–µ—Å—è—Ü",
    "üíé 3 –º–µ—Å—è—Ü–∞",
    "üíé 12 –º–µ—Å—è—Ü–µ–≤",
}


@router.message(F.text)
async def handle_chat(message: Message) -> None:
    if not message.text:
        return
    if message.text.startswith("/"):
        return
    if message.text in _MENU_TEXTS:
        return

    tg_user = message.from_user
    user = await ensure_user(tg_user)
    mode = await get_current_mode(user)
    style = infer_style_from_text(message.text)

    thinking_msg = await message.answer("‚è≥ –î—É–º–∞—é –Ω–∞–¥ –æ—Ç–≤–µ—Ç–æ–º...")

    try:
        parts = []
        async for chunk in llm_client.ask_stream(
            user_prompt=message.text,
            mode=mode,
            style=style,
        ):
            parts.append(chunk)
            await thinking_msg.edit_text("".join(parts))
            await asyncio.sleep(0.05)

        full_text = "".join(parts)
        tokens_used = estimate_tokens(full_text)
        await increment_usage(user["id"], tokens_used)
    except Exception:
        await thinking_msg.edit_text(
            "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏.\n"
            "–ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ —á—É—Ç—å –ø–æ–∑–∂–µ –∏–ª–∏ –∏–∑–º–µ–Ω–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –∑–∞–ø—Ä–æ—Å–∞."
        )
